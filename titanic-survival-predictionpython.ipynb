{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-22T01:51:15.756929Z","iopub.execute_input":"2022-04-22T01:51:15.757351Z","iopub.status.idle":"2022-04-22T01:51:15.788597Z","shell.execute_reply.started":"2022-04-22T01:51:15.757214Z","shell.execute_reply":"2022-04-22T01:51:15.787957Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Import usefull liabraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, data manupulation\nimport seaborn as sns # data visualization\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\n\n#import models (Algorithms)\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:51:20.229785Z","iopub.execute_input":"2022-04-22T01:51:20.230567Z","iopub.status.idle":"2022-04-22T01:51:20.844025Z","shell.execute_reply.started":"2022-04-22T01:51:20.230522Z","shell.execute_reply":"2022-04-22T01:51:20.842924Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# import the dataset both train and test data\ntrain_df = pd.read_csv('../input/titanic-dataset/train.csv')\ntest_df = pd.read_csv('../input/titanic-dataset/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:51:36.003403Z","iopub.execute_input":"2022-04-22T01:51:36.003725Z","iopub.status.idle":"2022-04-22T01:51:36.023418Z","shell.execute_reply.started":"2022-04-22T01:51:36.003688Z","shell.execute_reply":"2022-04-22T01:51:36.022311Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# combine the train and test data to one list\ndf = [train_df, test_df]","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:11:34.462421Z","iopub.execute_input":"2022-04-22T02:11:34.462735Z","iopub.status.idle":"2022-04-22T02:11:34.467505Z","shell.execute_reply.started":"2022-04-22T02:11:34.462704Z","shell.execute_reply":"2022-04-22T02:11:34.466659Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# printing the first 5 rows of the train_df data\n# head command will output the first 5 rows of the dataset as default, if you want more rows then 5, you can specifically mention on the brackets like train_df.head(10)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:51:38.832662Z","iopub.execute_input":"2022-04-22T01:51:38.833132Z","iopub.status.idle":"2022-04-22T01:51:38.854241Z","shell.execute_reply.started":"2022-04-22T01:51:38.833097Z","shell.execute_reply":"2022-04-22T01:51:38.853381Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# printing the first 5 rows of the test_df data\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:51:40.193908Z","iopub.execute_input":"2022-04-22T01:51:40.194196Z","iopub.status.idle":"2022-04-22T01:51:40.209875Z","shell.execute_reply.started":"2022-04-22T01:51:40.194155Z","shell.execute_reply":"2022-04-22T01:51:40.209019Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# print the last 5 rows of the train_df\n# tail command will output the last 5 rows of the dataset as default, if you want more rows then 5, you can specifically mention on the brackets like train_df.tail(10)\ntrain_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:51:41.608032Z","iopub.execute_input":"2022-04-22T01:51:41.608577Z","iopub.status.idle":"2022-04-22T01:51:41.626542Z","shell.execute_reply.started":"2022-04-22T01:51:41.608525Z","shell.execute_reply":"2022-04-22T01:51:41.625686Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# print the last 5 rows of the test_df\ntest_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:51:43.032092Z","iopub.execute_input":"2022-04-22T01:51:43.032421Z","iopub.status.idle":"2022-04-22T01:51:43.048514Z","shell.execute_reply.started":"2022-04-22T01:51:43.032387Z","shell.execute_reply":"2022-04-22T01:51:43.047412Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# check the shape of the dataset, this can help you to understand how many rows and columns in the dataset\nprint(f\"the train data has {train_df.shape[0]} rows and {train_df.shape[1]} columns\")\nprint(f\"the test data has {test_df.shape[0]} rows and {test_df.shape[1]} columns\") # Note: test data doesn't contain the target column","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:51:45.113271Z","iopub.execute_input":"2022-04-22T01:51:45.113596Z","iopub.status.idle":"2022-04-22T01:51:45.120150Z","shell.execute_reply.started":"2022-04-22T01:51:45.113561Z","shell.execute_reply":"2022-04-22T01:51:45.118957Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# pandas 'info()' command will give you a more information about data, like each column datatype, non-null values count etc.\ntrain_df.info()\nprint('-'*30)\ntest_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:51:47.545900Z","iopub.execute_input":"2022-04-22T01:51:47.546422Z","iopub.status.idle":"2022-04-22T01:51:47.571072Z","shell.execute_reply.started":"2022-04-22T01:51:47.546372Z","shell.execute_reply":"2022-04-22T01:51:47.569976Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# check the Null or Missing values in each column of train data\ntrain_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:51:50.096602Z","iopub.execute_input":"2022-04-22T01:51:50.097133Z","iopub.status.idle":"2022-04-22T01:51:50.108116Z","shell.execute_reply.started":"2022-04-22T01:51:50.097091Z","shell.execute_reply":"2022-04-22T01:51:50.107193Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"In train data we have some Missing or Null values on Age,Cabin and Embarked columns, we will fill these Null values using some methods in data cleaning","metadata":{}},{"cell_type":"code","source":"# check the Null or Missing values in each column of test data\ntest_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:51:54.841981Z","iopub.execute_input":"2022-04-22T01:51:54.842431Z","iopub.status.idle":"2022-04-22T01:51:54.852366Z","shell.execute_reply.started":"2022-04-22T01:51:54.842394Z","shell.execute_reply":"2022-04-22T01:51:54.851441Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"In test data we have some Missing or Null values on Age,Fare and Cabin columns, we will fill these Null values using some methods in data preprocessing","metadata":{}},{"cell_type":"code","source":"# check the survival rate of pclass\ntrain_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:51:58.297943Z","iopub.execute_input":"2022-04-22T01:51:58.298416Z","iopub.status.idle":"2022-04-22T01:51:58.313599Z","shell.execute_reply.started":"2022-04-22T01:51:58.298374Z","shell.execute_reply":"2022-04-22T01:51:58.312796Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#visual representation of survival rate per Pclass\nsns.barplot(x='Pclass',y='Survived',data=train_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:52:00.130365Z","iopub.execute_input":"2022-04-22T01:52:00.130696Z","iopub.status.idle":"2022-04-22T01:52:00.434248Z","shell.execute_reply.started":"2022-04-22T01:52:00.130652Z","shell.execute_reply":"2022-04-22T01:52:00.433301Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"We can clearly see the above barplot has higher Survival rate on Pclass-1 ","metadata":{}},{"cell_type":"code","source":"#survival rate based on sex. Female=0 and Male=1\ntrain_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:52:05.320250Z","iopub.execute_input":"2022-04-22T01:52:05.320540Z","iopub.status.idle":"2022-04-22T01:52:05.335980Z","shell.execute_reply.started":"2022-04-22T01:52:05.320510Z","shell.execute_reply":"2022-04-22T01:52:05.335061Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#Visual representation of survival rate\nsns.barplot(x='Sex',y='Survived',data=train_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:52:07.330185Z","iopub.execute_input":"2022-04-22T01:52:07.330626Z","iopub.status.idle":"2022-04-22T01:52:07.586476Z","shell.execute_reply.started":"2022-04-22T01:52:07.330596Z","shell.execute_reply":"2022-04-22T01:52:07.585808Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"In the above barplot Female are the higer survival rate then Male","metadata":{}},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"Now that we can have an idea of what types of data are in the dataset and what data is missing on dataset, we can clean or wrangling the data. We mainly focus on transform the string data to Numerical data and we can fill Missing or Null values with some methods.If any column is not usefull for Prediction we will drop that columns. and finally we transform all data to Numerical and Continuous because Machine can understand only Numerical data.","metadata":{}},{"cell_type":"code","source":"# we can convert Sex Column into Numerical values, Female=1, Male=0\n# we can clean the data both train and test data, we already combined train and test data into one dataset(df) we will use this dataset to cleaning the data\nfor data in df:\n    data['Sex']=data['Sex'].map({'female':1, 'male':0}).astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:20:35.487896Z","iopub.execute_input":"2022-04-22T02:20:35.488331Z","iopub.status.idle":"2022-04-22T02:20:35.497216Z","shell.execute_reply.started":"2022-04-22T02:20:35.488293Z","shell.execute_reply":"2022-04-22T02:20:35.496272Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# check the Sex column in train and test data if the values are affected or not\nprint(train_df.head())\nprint('-'*30)\nprint(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:23:00.007946Z","iopub.execute_input":"2022-04-22T02:23:00.008235Z","iopub.status.idle":"2022-04-22T02:23:00.024633Z","shell.execute_reply.started":"2022-04-22T02:23:00.008205Z","shell.execute_reply":"2022-04-22T02:23:00.023629Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# compute mean and standard deviation of Age column\nage_mean = train_df['Age'].mean()\nage_std = train_df['Age'].std()\n\n# Number of NaN or Missing values on Age Column\nnum_na = train_df['Age'].isnull().sum()\n\n# Now we can generate Random ages from mean and Standard deviation\nrandom_vals = age_mean + age_std * np.random.randn(num_na)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:36:48.423512Z","iopub.execute_input":"2022-04-22T02:36:48.423807Z","iopub.status.idle":"2022-04-22T02:36:48.430116Z","shell.execute_reply.started":"2022-04-22T02:36:48.423776Z","shell.execute_reply":"2022-04-22T02:36:48.429432Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Now we can replace Age NaN values with random_vals\ntrain_df.loc[train_df['Age'].isna(), 'Age'] = random_vals\n\n# Ages are replaced with Continues values, Now we can convert into Whole Number\ntrain_df['Age'] = train_df['Age'].astype(np.int64)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:37:09.431725Z","iopub.execute_input":"2022-04-22T02:37:09.432007Z","iopub.status.idle":"2022-04-22T02:37:09.438215Z","shell.execute_reply.started":"2022-04-22T02:37:09.431979Z","shell.execute_reply":"2022-04-22T02:37:09.437536Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# check the train_df and test_df dataset[Age] if the values are affected are not\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:39:05.284783Z","iopub.execute_input":"2022-04-22T02:39:05.285085Z","iopub.status.idle":"2022-04-22T02:39:05.300079Z","shell.execute_reply.started":"2022-04-22T02:39:05.285055Z","shell.execute_reply":"2022-04-22T02:39:05.299331Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# checking the Null values on Age column\nprint(train_df['Age'].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:40:59.783119Z","iopub.execute_input":"2022-04-22T02:40:59.783802Z","iopub.status.idle":"2022-04-22T02:40:59.788480Z","shell.execute_reply.started":"2022-04-22T02:40:59.783767Z","shell.execute_reply":"2022-04-22T02:40:59.787888Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# compute mean and standard deviation of Age column test_dataset\nage_mean = test_df['Age'].mean()\nage_std = test_df['Age'].std()\n\n# Number of NaN or Missing values on Age Column\nnum_na = test_df['Age'].isnull().sum()\n\n# Now we can generate Random ages from mean and Standard deviation\nrandom_vals = age_mean + age_std * np.random.randn(num_na)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:42:59.091906Z","iopub.execute_input":"2022-04-22T02:42:59.092239Z","iopub.status.idle":"2022-04-22T02:42:59.099709Z","shell.execute_reply.started":"2022-04-22T02:42:59.092203Z","shell.execute_reply":"2022-04-22T02:42:59.098632Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Now we can replace Age NaN values with random_vals\ntest_df.loc[test_df['Age'].isna(), 'Age'] = random_vals\n\n# Ages are replaced with Continues values, Now we can convert into Whole Number\ntest_df['Age'] = test_df['Age'].astype(np.int64)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:43:46.666225Z","iopub.execute_input":"2022-04-22T02:43:46.666530Z","iopub.status.idle":"2022-04-22T02:43:46.674168Z","shell.execute_reply.started":"2022-04-22T02:43:46.666496Z","shell.execute_reply":"2022-04-22T02:43:46.673175Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# check the dataset if the values are affected are not\ntest_df['Age'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:45:39.222830Z","iopub.execute_input":"2022-04-22T02:45:39.223686Z","iopub.status.idle":"2022-04-22T02:45:39.229025Z","shell.execute_reply.started":"2022-04-22T02:45:39.223630Z","shell.execute_reply":"2022-04-22T02:45:39.228178Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row= 'Pclass', col= 'Sex', size = 2.4, aspect = 2.6)\ngrid.map(plt.hist, 'Age', alpha= .4, bins=10, color= 'blue')\nplt.ylim((0,80))\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:47:09.598397Z","iopub.execute_input":"2022-04-22T02:47:09.598682Z","iopub.status.idle":"2022-04-22T02:47:10.859622Z","shell.execute_reply.started":"2022-04-22T02:47:09.598652Z","shell.execute_reply":"2022-04-22T02:47:10.858778Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# find the most frequently used port\nport = train_df['Embarked'].dropna().mode()[0]\nport","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:48:59.634317Z","iopub.execute_input":"2022-04-22T02:48:59.634664Z","iopub.status.idle":"2022-04-22T02:48:59.643694Z","shell.execute_reply.started":"2022-04-22T02:48:59.634629Z","shell.execute_reply":"2022-04-22T02:48:59.642829Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# fill the Embarked column with most frequently used port\nfor data in df:\n    data['Embarked'] = data['Embarked'].fillna(port)\n\n# check the Survival rate on Embarked Column\ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], \n                                as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:51:12.134528Z","iopub.execute_input":"2022-04-22T02:51:12.134879Z","iopub.status.idle":"2022-04-22T02:51:12.153618Z","shell.execute_reply.started":"2022-04-22T02:51:12.134842Z","shell.execute_reply":"2022-04-22T02:51:12.152889Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# check the train_df and test_df for any other missing values are remain\nprint(train_df.isnull().sum())\nprint('-'*30)\nprint(test_df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:52:56.295887Z","iopub.execute_input":"2022-04-22T02:52:56.296340Z","iopub.status.idle":"2022-04-22T02:52:56.307387Z","shell.execute_reply.started":"2022-04-22T02:52:56.296307Z","shell.execute_reply":"2022-04-22T02:52:56.306222Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"for data in df:\n    data['Fare'] = data['Fare'].fillna(0)\n    data['Fare'] = data['Fare'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:55:13.069681Z","iopub.execute_input":"2022-04-22T02:55:13.070457Z","iopub.status.idle":"2022-04-22T02:55:13.078074Z","shell.execute_reply.started":"2022-04-22T02:55:13.070413Z","shell.execute_reply":"2022-04-22T02:55:13.076805Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# convert categorical embarked feature to numeric values\n\nfor data in df:\n    data['Embarked'] = data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\n# check the dataset to verify Embarked column is affected are not.\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:59:05.788241Z","iopub.execute_input":"2022-04-22T02:59:05.788529Z","iopub.status.idle":"2022-04-22T02:59:05.805752Z","shell.execute_reply.started":"2022-04-22T02:59:05.788501Z","shell.execute_reply":"2022-04-22T02:59:05.804733Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# Now we can drop some columns which are not usefull to predictions\n# the columns we are droping here is passenderID, Name, Ticket, Cabin\n\ntrain_df = train_df.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)\ntest_df = test_df.drop(['Name','Ticket','Cabin'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T03:06:08.607271Z","iopub.execute_input":"2022-04-22T03:06:08.607991Z","iopub.status.idle":"2022-04-22T03:06:08.614624Z","shell.execute_reply.started":"2022-04-22T03:06:08.607954Z","shell.execute_reply":"2022-04-22T03:06:08.613843Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T03:06:34.242022Z","iopub.execute_input":"2022-04-22T03:06:34.242447Z","iopub.status.idle":"2022-04-22T03:06:34.247193Z","shell.execute_reply.started":"2022-04-22T03:06:34.242413Z","shell.execute_reply":"2022-04-22T03:06:34.246585Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"age_hist = sns.FacetGrid(train_df, col= 'Survived')\nage_hist.map(plt.hist, 'Age', bins = 20, color = \"Orange\")","metadata":{"execution":{"iopub.status.busy":"2022-04-22T03:09:50.450568Z","iopub.execute_input":"2022-04-22T03:09:50.450906Z","iopub.status.idle":"2022-04-22T03:09:50.859558Z","shell.execute_reply.started":"2022-04-22T03:09:50.450874Z","shell.execute_reply":"2022-04-22T03:09:50.858727Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"Throughout the cleaning process I noticed a few relationships between age and survival. Most passangers in this data set are in the age range 15-35 years old. The oldest surviving passanger was 80 years old and children under the age of 4 had a high survival rate","metadata":{}},{"cell_type":"code","source":"# Survival by Age and Passendger Class\ngrid = sns.FacetGrid(train_df, col = 'Survived', row = 'Pclass', size = 2.3, aspect = 1.5)\ngrid.map(plt.hist, 'Age', alpha = .5, bins = 25, color = \"red\")\ngrid.add_legend();","metadata":{"execution":{"iopub.status.busy":"2022-04-22T03:11:45.687187Z","iopub.execute_input":"2022-04-22T03:11:45.687800Z","iopub.status.idle":"2022-04-22T03:11:47.123715Z","shell.execute_reply.started":"2022-04-22T03:11:45.687763Z","shell.execute_reply":"2022-04-22T03:11:47.122821Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Survival by Sex, Passenger class and port \ngrid = sns.FacetGrid(train_df, row='Embarked', size=2.3, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T03:15:12.354775Z","iopub.execute_input":"2022-04-22T03:15:12.355073Z","iopub.status.idle":"2022-04-22T03:15:13.612461Z","shell.execute_reply.started":"2022-04-22T03:15:12.355034Z","shell.execute_reply":"2022-04-22T03:15:13.611358Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"# Prediction with Some Models\n\n1. Logistic Regression\n2. k-Nearest Neighbors\n3. Random Fores\n4. Decision Tree","metadata":{}},{"cell_type":"code","source":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T03:26:08.152655Z","iopub.execute_input":"2022-04-22T03:26:08.152992Z","iopub.status.idle":"2022-04-22T03:26:08.161166Z","shell.execute_reply.started":"2022-04-22T03:26:08.152955Z","shell.execute_reply":"2022-04-22T03:26:08.160213Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression\nLogistic regression is a statisical model used to handle classification problems. Logistic regression is a process of modeling the probablity of a discrete outcome given an input variable. In other words it measures the realatoinship between the categorical depedent feature and one of more independent features","metadata":{}},{"cell_type":"code","source":"# Survival Prediction using LogisticRegression\n\nlog_model = LogisticRegression()\nlog_model.fit(X_train, Y_train)\nY_pred = log_model.predict(X_test)\naccuracy_log = round(log_model.score(X_train, Y_train) * 100, 2)\nprint(f\" accuracy score with Random Forest : {accuracy_log}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-22T03:36:20.725844Z","iopub.execute_input":"2022-04-22T03:36:20.726433Z","iopub.status.idle":"2022-04-22T03:36:20.765715Z","shell.execute_reply.started":"2022-04-22T03:36:20.726399Z","shell.execute_reply":"2022-04-22T03:36:20.765091Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree\n\nDecision Trees are a non-parametric surpervised learning method used for classifications and regression.The goal is to use a tree like model to evaluate decisions and their possible outcomes including things such as probablity, cost, and other relavent features. Decision tree models","metadata":{}},{"cell_type":"code","source":"# Survival Prediction using Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nprint(f\" accuracy score with Random Forest : {acc_decision_tree}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-22T03:33:16.100264Z","iopub.execute_input":"2022-04-22T03:33:16.100797Z","iopub.status.idle":"2022-04-22T03:33:16.112845Z","shell.execute_reply.started":"2022-04-22T03:33:16.100734Z","shell.execute_reply":"2022-04-22T03:33:16.112143Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest\nThe random forest analysis is a classification algorithm consisting of many decision trees. However is utilizes a bagging method and randomness features.","metadata":{}},{"cell_type":"code","source":"# Survival Prediction using Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nprint(f\" accuracy score with Random Forest : {acc_random_forest}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-22T03:32:51.335532Z","iopub.execute_input":"2022-04-22T03:32:51.335849Z","iopub.status.idle":"2022-04-22T03:32:51.646920Z","shell.execute_reply.started":"2022-04-22T03:32:51.335817Z","shell.execute_reply":"2022-04-22T03:32:51.646071Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"## K-Nearest Neighbor\n\nThe K-nearest Neighbor algorithm is a data classification method for estimating the likelihood of the data point will beocome a member of one group or another based on what the group data points nearest to is belong to.","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nprint(f\" accuracy score with Random Forest : {acc_knn}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-22T03:34:39.971224Z","iopub.execute_input":"2022-04-22T03:34:39.971799Z","iopub.status.idle":"2022-04-22T03:34:40.033473Z","shell.execute_reply.started":"2022-04-22T03:34:39.971759Z","shell.execute_reply":"2022-04-22T03:34:40.032622Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"# Each Model performance","metadata":{}},{"cell_type":"code","source":"# Create a DataFrame with all models Accuracy Score with Model\nmodels = pd.DataFrame({\n   'Model': ['KNN', 'Logistic Regression', 'Random Forest',  'Decision Tree'],\n    'Score': [ acc_knn,accuracy_log, acc_random_forest, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T03:40:29.716757Z","iopub.execute_input":"2022-04-22T03:40:29.717080Z","iopub.status.idle":"2022-04-22T03:40:29.730493Z","shell.execute_reply.started":"2022-04-22T03:40:29.717039Z","shell.execute_reply":"2022-04-22T03:40:29.729556Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}